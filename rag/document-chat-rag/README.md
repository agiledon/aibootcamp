# KFlow RAG - Intelligent Document Q&A System with ChromaDB

## Overview

KFlow RAG is an intelligent document question-answering system based on ChromaDB vector database, supporting multiple document formats for upload, processing, and intelligent Q&A. The system adopts the MVP architecture pattern, integrating LlamaIndex framework, DeepSeek LLM, and Ollama embedding models, providing persistent document storage and cross-session retrieval capabilities.

## Features

### ğŸ¯ Core Features
- **Persistent Storage**: Document embeddings stored in ChromaDB database
- **Collection Management**: Uses "kflow" as the default collection name
- **File Replacement**: Same-name files automatically replace old versions
- **Global Retrieval**: Retrieve relevant documents from the entire collection
- **Intelligent Q&A**: Supports full knowledge base and specific document retrieval
- **Streaming Response**: Real-time answer generation for better user experience

### ğŸ“ File Structure
- `chroma_repository.py`: ChromaDB database operations class
- `custom_query_engine.py`: Custom query engine with document filtering
- `model.py`: Core business logic integrating ChromaDB storage and retrieval
- `controller.py`: Controller coordinating View and Model interactions
- `view.py`: View layer with Streamlit user interface
- `app.py`: Main application entry point

## Installation and Configuration

### 1. Install Dependencies

#### Using uv (Recommended)
```bash
# Install project dependencies
uv sync

# Or using pip
pip install -e .
```

### 2. Start Ollama Service

```bash
# Start Ollama service
ollama serve

# Install embedding model
ollama pull nomic-embed-text
```

### 3. Configure DeepSeek API

```bash
# Set DeepSeek API Key
export DEEPSEEK_API_KEY="your_api_key_here"
```

### 4. Verify Installation
```bash
# Check Ollama service status
curl http://localhost:11434/api/tags

# Check installed models
ollama list
```

## Usage

### Starting the Application

#### Method 1: Direct Start (Recommended)
```bash
# Ensure Ollama service is running
ollama serve

# Start the application
uv run streamlit run app.py
```

#### Method 2: Using Ollama Startup Script
```bash
# Start Ollama service
python start_ollama.py

# Start the application in another terminal
uv run streamlit run app.py
```

### Document Operation Workflow

1. **Upload Documents**: Supports PDF, Word, Markdown, CSV, TXT files
2. **Automatic Storage**: Documents automatically stored in ChromaDB collection "kflow"
3. **Select Retrieval Scope**: Supports full knowledge base or specific document retrieval
4. **Intelligent Q&A**: RAG-based Q&A with streaming responses

## Technical Architecture

### ChromaRepository Class
```python
class ChromaRepository:
    def __init__(self, collection_name="kflow")
    def store_documents(self, documents, file_name, embed_model, progress_callback=None)
    def get_query_engine(self, file_names=None, llm=None, streaming=True)
    def get_collection_info(self)
    def clear_collection(self)
    def update_vector_store_with_new_documents(self, embed_model)
```

### FilteredQueryEngine Class
```python
class FilteredQueryEngine(BaseQueryEngine):
    def __init__(self, index, target_files=None, similarity_top_k=5, streaming=True, llm=None)
    def query(self, query_str)
    def set_target_files(self, target_files)
    def get_target_files(self)
```

### Storage Strategy
- **Collection Name**: kflow
- **Vector Dimension**: 768 (nomic-embed-text model)
- **Document Splitting**: 1024 character chunks, 200 character overlap
- **Metadata**: Includes filename and source information

### Retrieval Strategy
- **Similarity Search**: Retrieve top 5 most relevant document chunks
- **Global Search**: Retrieve from entire collection, not limited to single files
- **Document Filtering**: Support filtering by filename
- **Streaming Response**: Real-time answer generation

## Troubleshooting

### Common Issues

#### 1. Ollama Service Connection Failed
```
Error: HTTP Request: POST http://localhost:11434/api/embed "HTTP/1.1 502 Bad Gateway"
Solution: Ensure Ollama service is running with nomic-embed-text model installed
Check:
  - curl http://localhost:11434/api/tags
  - ollama list
  - ollama pull nomic-embed-text
Note: Embedding model is required for document vector generation
```

#### 2. DeepSeek API Connection Failed
```
Error: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 401 Unauthorized"
Solution: Ensure correct DeepSeek API Key is set
Check:
  - echo $DEEPSEEK_API_KEY
  - Verify API Key is valid with sufficient quota
```

#### 3. ChromaDB Initialization Failed
```
Error: Failed to create ChromaDB collection
Solution: Check ChromaDB dependencies are correctly installed
Check:
  - pip list | grep chromadb
  - Ensure chromadb>=1.1.0 is installed
```

#### 4. Callback Manager Error
```
Error: IndexError: pop from empty list
Solution: System has automatic recovery mechanism, will reset callback manager and retry
Note: This is caused by llama_index callback manager state inconsistency, handled automatically
```

#### 5. Out of Memory
```
Error: Out of memory
Solution: Increase system memory or adjust document splitting parameters
```

### System Status Check
```python
# Check service status
chroma_status, ollama_status = model.check_services_status()
print(f"ChromaDB Status: {chroma_status}")
print(f"Ollama Status: {ollama_status}")

# Get ChromaDB collection info
info = model.get_chroma_info()
print(f"Collection Status: {info['status']}")
print(f"Document Count: {info['total_documents']}")
```

## Configuration Options

### Environment Variables
```bash
# DeepSeek API Key
export DEEPSEEK_API_KEY="your_api_key_here"

# ChromaDB Collection Name (optional, defaults to kflow)
export CHROMA_COLLECTION="kflow"

# Ollama Service URL (optional, defaults to localhost:11434)
export OLLAMA_BASE_URL="http://localhost:11434"
```

### Code Configuration
```python
# Custom ChromaDB configuration
chroma_repo = ChromaRepository(
    collection_name="my_collection"
)

# Custom query engine configuration
query_engine = FilteredQueryEngine(
    index=index,
    target_files=["specific_file.pdf"],  # Specific file retrieval
    similarity_top_k=10,  # Retrieve more results
    streaming=True
)
```

## Performance Optimization

### Recommended Configuration
- **Memory**: At least 8GB RAM
- **Storage**: SSD drive, at least 10GB available space
- **CPU**: 4+ cores
- **Network**: Stable network connection (for DeepSeek API)

### Tuning Parameters
```python
# Document splitting parameters
text_splitter = SentenceSplitter(
    chunk_size=1024,      # Chunk size
    chunk_overlap=200,    # Overlap size
    separator=" "         # Separator
)

# Retrieval parameters
query_engine = FilteredQueryEngine(
    index=index,
    similarity_top_k=5,   # Number of results
    streaming=True        # Streaming response
)
```

## Monitoring and Maintenance

### Health Check
```python
# Get ChromaDB collection info
info = model.get_chroma_info()
print(f"Status: {info['status']}")
print(f"Storage Type: {info['storage_type']}")
print(f"Document Count: {info['total_documents']}")
```

### Data Cleanup
```python
# Clear entire collection
model.clear_chroma_collection()
```

## Changelog

### v2.0.0
- âœ… Migrated to ChromaDB vector database
- âœ… Integrated DeepSeek LLM and Ollama embedding models
- âœ… Implemented custom filtered query engine
- âœ… Support for document filtering and full knowledge base retrieval
- âœ… Fixed callback manager error handling
- âœ… Optimized error recovery mechanism

### v1.0.0
- âœ… Integrated Milvus vector database
- âœ… Implemented persistent document storage
- âœ… Added file replacement functionality
- âœ… Added graceful degradation mechanism
- âœ… Optimized retrieval performance

## Support

If you encounter issues, please check:
1. Ollama service is running properly
2. DeepSeek API Key is valid
3. Network connection is stable
4. System resources are sufficient
5. Dependencies are correctly installed

---

# KFlow RAG - åŸºäºChromaDBçš„æ™ºèƒ½æ–‡æ¡£é—®ç­”ç³»ç»Ÿ

## æ¦‚è¿°

KFlow RAGæ˜¯ä¸€ä¸ªåŸºäºChromaDBå‘é‡æ•°æ®åº“çš„æ™ºèƒ½æ–‡æ¡£é—®ç­”ç³»ç»Ÿï¼Œæ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼çš„ä¸Šä¼ ã€å¤„ç†å’Œæ™ºèƒ½é—®ç­”ã€‚ç³»ç»Ÿé‡‡ç”¨MVPæ¶æ„æ¨¡å¼ï¼Œé›†æˆäº†LlamaIndexæ¡†æ¶ã€DeepSeek LLMå’ŒOllamaåµŒå…¥æ¨¡å‹ï¼Œæä¾›æŒä¹…åŒ–çš„æ–‡æ¡£å­˜å‚¨å’Œè·¨ä¼šè¯çš„æ£€ç´¢åŠŸèƒ½ã€‚

## åŠŸèƒ½ç‰¹æ€§

### ğŸ¯ æ ¸å¿ƒåŠŸèƒ½
- **æŒä¹…åŒ–å­˜å‚¨**: æ–‡æ¡£åµŒå…¥å‘é‡å­˜å‚¨åœ¨ChromaDBæ•°æ®åº“ä¸­
- **é›†åˆç®¡ç†**: ä½¿ç”¨"kflow"ä½œä¸ºé»˜è®¤é›†åˆåç§°
- **æ–‡ä»¶æ›¿æ¢**: åŒåæ–‡ä»¶ä¼šè‡ªåŠ¨æ›¿æ¢æ—§ç‰ˆæœ¬
- **å…¨å±€æ£€ç´¢**: ä»æ•´ä¸ªé›†åˆä¸­æ£€ç´¢ç›¸å…³æ–‡æ¡£
- **æ™ºèƒ½é—®ç­”**: æ”¯æŒå…¨çŸ¥è¯†åº“æ£€ç´¢å’Œç‰¹å®šæ–‡æ¡£æ£€ç´¢
- **æµå¼å“åº”**: å®æ—¶ç”Ÿæˆå›ç­”ï¼Œæä¾›æ›´å¥½çš„ç”¨æˆ·ä½“éªŒ

### ğŸ“ æ–‡ä»¶ç»“æ„
- `chroma_repository.py`: ChromaDBæ•°æ®åº“æ“ä½œç±»
- `custom_query_engine.py`: è‡ªå®šä¹‰æŸ¥è¯¢å¼•æ“ï¼Œæ”¯æŒæ–‡æ¡£è¿‡æ»¤
- `model.py`: æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ï¼Œé›†æˆChromaDBå­˜å‚¨å’Œæ£€ç´¢åŠŸèƒ½
- `controller.py`: æ§åˆ¶å™¨ï¼Œåè°ƒViewå’ŒModelä¹‹é—´çš„äº¤äº’
- `view.py`: è§†å›¾å±‚ï¼ŒStreamlitç”¨æˆ·ç•Œé¢
- `app.py`: ä¸»åº”ç”¨å…¥å£

## å®‰è£…å’Œé…ç½®

### 1. å®‰è£…ä¾èµ–

#### ä½¿ç”¨ uvï¼ˆæ¨èï¼‰
```bash
# å®‰è£…é¡¹ç›®ä¾èµ–
uv sync

# æˆ–è€…ä½¿ç”¨ pip
pip install -e .
```

### 2. å¯åŠ¨ Ollama æœåŠ¡

```bash
# å¯åŠ¨ Ollama æœåŠ¡
ollama serve

# å®‰è£…åµŒå…¥æ¨¡å‹
ollama pull nomic-embed-text
```

### 3. é…ç½® DeepSeek API

```bash
# è®¾ç½® DeepSeek API Key
export DEEPSEEK_API_KEY="your_api_key_here"
```

### 4. éªŒè¯å®‰è£…
```bash
# æ£€æŸ¥ Ollama æœåŠ¡çŠ¶æ€
curl http://localhost:11434/api/tags

# æ£€æŸ¥å·²å®‰è£…çš„æ¨¡å‹
ollama list
```

## ä½¿ç”¨æ–¹æ³•

### å¯åŠ¨åº”ç”¨

#### æ–¹æ³•1: ç›´æ¥å¯åŠ¨ï¼ˆæ¨èï¼‰
```bash
# ç¡®ä¿ Ollama æœåŠ¡æ­£åœ¨è¿è¡Œ
ollama serve

# å¯åŠ¨åº”ç”¨
uv run streamlit run app.py
```

#### æ–¹æ³•2: ä½¿ç”¨ Ollama å¯åŠ¨è„šæœ¬
```bash
# å¯åŠ¨ Ollama æœåŠ¡
python start_ollama.py

# åœ¨å¦ä¸€ä¸ªç»ˆç«¯å¯åŠ¨åº”ç”¨
uv run streamlit run app.py
```

### æ–‡æ¡£æ“ä½œæµç¨‹

1. **ä¸Šä¼ æ–‡æ¡£**: æ”¯æŒPDFã€Wordã€Markdownã€CSVã€TXTæ–‡ä»¶
2. **è‡ªåŠ¨å­˜å‚¨**: æ–‡æ¡£è‡ªåŠ¨å­˜å‚¨åˆ°ChromaDBé›†åˆ"kflow"
3. **é€‰æ‹©æ£€ç´¢èŒƒå›´**: æ”¯æŒå…¨çŸ¥è¯†åº“æ£€ç´¢æˆ–ç‰¹å®šæ–‡æ¡£æ£€ç´¢
4. **æ™ºèƒ½é—®ç­”**: åŸºäºæ£€ç´¢ç»“æœè¿›è¡ŒRAGé—®ç­”ï¼Œæ”¯æŒæµå¼å“åº”

## æŠ€æœ¯æ¶æ„

### ChromaRepositoryç±»
```python
class ChromaRepository:
    def __init__(self, collection_name="kflow")
    def store_documents(self, documents, file_name, embed_model, progress_callback=None)
    def get_query_engine(self, file_names=None, llm=None, streaming=True)
    def get_collection_info(self)
    def clear_collection(self)
    def update_vector_store_with_new_documents(self, embed_model)
```

### FilteredQueryEngineç±»
```python
class FilteredQueryEngine(BaseQueryEngine):
    def __init__(self, index, target_files=None, similarity_top_k=5, streaming=True, llm=None)
    def query(self, query_str)
    def set_target_files(self, target_files)
    def get_target_files(self)
```

### å­˜å‚¨ç­–ç•¥
- **é›†åˆåç§°**: kflow
- **å‘é‡ç»´åº¦**: 768ï¼ˆnomic-embed-textæ¨¡å‹ï¼‰
- **æ–‡æ¡£åˆ†å‰²**: 1024å­—ç¬¦å—ï¼Œ200å­—ç¬¦é‡å 
- **å…ƒæ•°æ®**: åŒ…å«æ–‡ä»¶åå’Œæ¥æºä¿¡æ¯

### æ£€ç´¢ç­–ç•¥
- **ç›¸ä¼¼åº¦æ£€ç´¢**: æ£€ç´¢å‰5ä¸ªæœ€ç›¸å…³æ–‡æ¡£ç‰‡æ®µ
- **å…¨å±€æœç´¢**: ä»æ•´ä¸ªé›†åˆä¸­æ£€ç´¢ï¼Œä¸é™äºå•ä¸ªæ–‡ä»¶
- **æ–‡æ¡£è¿‡æ»¤**: æ”¯æŒæŒ‰æ–‡ä»¶åè¿‡æ»¤æ£€ç´¢ç»“æœ
- **æµå¼å“åº”**: æ”¯æŒå®æ—¶æµå¼å›ç­”ç”Ÿæˆ

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. Ollama æœåŠ¡è¿æ¥å¤±è´¥
```
é”™è¯¯: HTTP Request: POST http://localhost:11434/api/embed "HTTP/1.1 502 Bad Gateway"
è§£å†³: ç¡®ä¿ Ollama æœåŠ¡æ­£å¸¸è¿è¡Œå¹¶å®‰è£… nomic-embed-text æ¨¡å‹
æ£€æŸ¥æ–¹æ³•: 
  - curl http://localhost:11434/api/tags
  - ollama list
  - ollama pull nomic-embed-text
è¯´æ˜: åµŒå…¥æ¨¡å‹ç”¨äºç”Ÿæˆæ–‡æ¡£å‘é‡ï¼Œå¿…é¡»æ­£å¸¸è¿è¡Œ
```

#### 2. DeepSeek API è¿æ¥å¤±è´¥
```
é”™è¯¯: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 401 Unauthorized"
è§£å†³: ç¡®ä¿è®¾ç½®äº†æ­£ç¡®çš„ DeepSeek API Key
æ£€æŸ¥æ–¹æ³•: 
  - echo $DEEPSEEK_API_KEY
  - ç¡®è®¤ API Key æœ‰æ•ˆä¸”æœ‰è¶³å¤Ÿçš„é…é¢
```

#### 3. ChromaDB åˆå§‹åŒ–å¤±è´¥
```
é”™è¯¯: Failed to create ChromaDB collection
è§£å†³: æ£€æŸ¥ ChromaDB ä¾èµ–æ˜¯å¦æ­£ç¡®å®‰è£…
æ£€æŸ¥æ–¹æ³•:
  - pip list | grep chromadb
  - ç¡®è®¤ chromadb>=1.1.0 å·²å®‰è£…
```

#### 4. å›è°ƒç®¡ç†å™¨é”™è¯¯
```
é”™è¯¯: IndexError: pop from empty list
è§£å†³: ç³»ç»Ÿå·²å®ç°è‡ªåŠ¨æ¢å¤æœºåˆ¶ï¼Œä¼šè‡ªåŠ¨é‡ç½®å›è°ƒç®¡ç†å™¨å¹¶é‡è¯•
è¯´æ˜: è¿™æ˜¯ç”±äº llama_index å›è°ƒç®¡ç†å™¨çŠ¶æ€ä¸ä¸€è‡´å¯¼è‡´çš„ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å¤„ç†
```

#### 5. å†…å­˜ä¸è¶³
```
é”™è¯¯: Out of memory
è§£å†³: å¢åŠ ç³»ç»Ÿå†…å­˜æˆ–è°ƒæ•´æ–‡æ¡£åˆ†å‰²å‚æ•°
```

### ç³»ç»ŸçŠ¶æ€æ£€æŸ¥
```python
# æ£€æŸ¥æœåŠ¡çŠ¶æ€
chroma_status, ollama_status = model.check_services_status()
print(f"ChromaDBçŠ¶æ€: {chroma_status}")
print(f"OllamaçŠ¶æ€: {ollama_status}")

# è·å– ChromaDB é›†åˆä¿¡æ¯
info = model.get_chroma_info()
print(f"é›†åˆçŠ¶æ€: {info['status']}")
print(f"æ–‡æ¡£æ•°é‡: {info['total_documents']}")
```

## é…ç½®é€‰é¡¹

### ç¯å¢ƒå˜é‡
```bash
# DeepSeek API Key
export DEEPSEEK_API_KEY="your_api_key_here"

# ChromaDB é›†åˆåç§°ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸º kflowï¼‰
export CHROMA_COLLECTION="kflow"

# Ollama æœåŠ¡åœ°å€ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸º localhost:11434ï¼‰
export OLLAMA_BASE_URL="http://localhost:11434"
```

### ä»£ç é…ç½®
```python
# è‡ªå®šä¹‰ ChromaDB é…ç½®
chroma_repo = ChromaRepository(
    collection_name="my_collection"
)

# è‡ªå®šä¹‰æŸ¥è¯¢å¼•æ“é…ç½®
query_engine = FilteredQueryEngine(
    index=index,
    target_files=["specific_file.pdf"],  # ç‰¹å®šæ–‡ä»¶æ£€ç´¢
    similarity_top_k=10,  # æ£€ç´¢æ›´å¤šç»“æœ
    streaming=True
)
```

## æ€§èƒ½ä¼˜åŒ–

### æ¨èé…ç½®
- **å†…å­˜**: è‡³å°‘8GB RAM
- **å­˜å‚¨**: SSDç¡¬ç›˜ï¼Œè‡³å°‘10GBå¯ç”¨ç©ºé—´
- **CPU**: 4æ ¸å¿ƒä»¥ä¸Š
- **ç½‘ç»œ**: ç¨³å®šçš„ç½‘ç»œè¿æ¥ï¼ˆç”¨äº DeepSeek APIï¼‰

### è°ƒä¼˜å‚æ•°
```python
# æ–‡æ¡£åˆ†å‰²å‚æ•°
text_splitter = SentenceSplitter(
    chunk_size=1024,      # å—å¤§å°
    chunk_overlap=200,    # é‡å å¤§å°
    separator=" "         # åˆ†éš”ç¬¦
)

# æ£€ç´¢å‚æ•°
query_engine = FilteredQueryEngine(
    index=index,
    similarity_top_k=5,   # æ£€ç´¢æ•°é‡
    streaming=True        # æµå¼å“åº”
)
```

## ç›‘æ§å’Œç»´æŠ¤

### å¥åº·æ£€æŸ¥
```python
# è·å– ChromaDB é›†åˆä¿¡æ¯
info = model.get_chroma_info()
print(f"çŠ¶æ€: {info['status']}")
print(f"å­˜å‚¨ç±»å‹: {info['storage_type']}")
print(f"æ–‡æ¡£æ•°é‡: {info['total_documents']}")
```

### æ•°æ®æ¸…ç†
```python
# æ¸…ç©ºæ•´ä¸ªé›†åˆ
model.clear_chroma_collection()
```

## æ›´æ–°æ—¥å¿—

### v2.0.0
- âœ… è¿ç§»åˆ° ChromaDB å‘é‡æ•°æ®åº“
- âœ… é›†æˆ DeepSeek LLM å’Œ Ollama åµŒå…¥æ¨¡å‹
- âœ… å®ç°è‡ªå®šä¹‰è¿‡æ»¤æŸ¥è¯¢å¼•æ“
- âœ… æ”¯æŒæ–‡æ¡£è¿‡æ»¤å’Œå…¨çŸ¥è¯†åº“æ£€ç´¢
- âœ… ä¿®å¤å›è°ƒç®¡ç†å™¨é”™è¯¯å¤„ç†
- âœ… ä¼˜åŒ–é”™è¯¯æ¢å¤æœºåˆ¶

### v1.0.0
- âœ… é›†æˆ Milvus å‘é‡æ•°æ®åº“
- âœ… å®ç°æ–‡æ¡£æŒä¹…åŒ–å­˜å‚¨
- âœ… æ”¯æŒæ–‡ä»¶æ›¿æ¢åŠŸèƒ½
- âœ… æ·»åŠ ä¼˜é›…é™çº§æœºåˆ¶
- âœ… ä¼˜åŒ–æ£€ç´¢æ€§èƒ½

## æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š
1. Ollama æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ
2. DeepSeek API Key æ˜¯å¦æœ‰æ•ˆ
3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸
4. ç³»ç»Ÿèµ„æºæ˜¯å¦å……è¶³
5. ä¾èµ–åŒ…æ˜¯å¦æ­£ç¡®å®‰è£…
